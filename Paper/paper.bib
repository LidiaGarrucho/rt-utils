@ARTICLE{Fedorov2012-ax,

      title     = "{3D} Slicer as an image computing platform for the Quantitative
                   Imaging Network",
      author    = "Fedorov, Andriy and Beichel, Reinhard and Kalpathy-Cramer,
                   Jayashree and Finet, Julien and Fillion-Robin, Jean-Christophe
                   and Pujol, Sonia and Bauer, Christian and Jennings, Dominique and
                   Fennessy, Fiona and Sonka, Milan and Buatti, John and Aylward,
                   Stephen and Miller, James V and Pieper, Steve and Kikinis, Ron",
      journal   = "Magn. Reson. Imaging",
      publisher = "Elsevier",
      volume    =  30,
      number    =  9,
      pages     = "1323--1341",
      month     =  nov,
      year      =  2012,
      language  = "en",
      doi       = "10.1016/j.mri.2012.05.001"
    }

@MISC{Creators_The_MONAI_Consortium_undated-or,
      title  = "Project {MONAI}",
      author = "{Creators The MONAI Consortium}",
      doi    =  "10.48550/arXiv.2211.02701"
    }

@ARTICLE{Perez-Garcia2021-jf,
      title     = "{TorchIO}: A Python library for efficient loading, preprocessing,
                   augmentation and patch-based sampling of medical images in deep
                   learning",
      author    = "P\'{e}rez-Garc\'{i}a, Fernando and Sparks, Rachel and Ourselin, S\'{e}bastien",
      journal   = "Comput. Methods Programs Biomed.",
      publisher = "Elsevier",
      volume    =  208,
      pages     =  106236,
      month     =  sep,
      year      =  2021,
      keywords  = "Data augmentation; Deep learning; Medical image computing;
                   Preprocessing",
      language  = "en",
      doi       = "10.1016/j.cmpb.2021.106236"
    }

@ARTICLE{Anderson2021-fp,
      title     = "Simple Python Module for Conversions Between {DICOM} Images and
                   Radiation Therapy Structures, Masks, and Prediction Arrays",
      author    = "Anderson, Brian M and Wahid, Kareem A and Brock, Kristy K",
      journal   = "Pract. Radiat. Oncol.",
      publisher = "Elsevier",
      volume    =  11,
      number    =  3,
      pages     = "226--229",
      month     =  feb,
      year      =  2021,
      language  = "en",
      doi       = "10.1016/j.prro.2021.02.003"
    }

@ARTICLE{Rufenacht2023-as,
      title     = "{PyRaDiSe}: A Python package for {DICOM}-{RT}-based
                   auto-segmentation pipeline construction and {DICOM}-{RT} data
                   conversion",
      author    = "R\"{u}fenacht, Elias and Kamath, Amith and Suter, Yannick and Poel,
                   Robert and Ermi\c{s}, Ekin and Scheib, Stefan and Reyes, Mauricio",
      journal   = "Comput. Methods Programs Biomed.",
      publisher = "Elsevier",
      volume    =  231,
      pages     =  107374,
      month     =  apr,
      year      =  2023,
      keywords  = "Auto-segmentation; DICOM; DICOM RT structure sets; DICOM RTSS
                   conversion; Deep learning; Radiotherapy",
      language  = "en",
      doi       = "10.2139/ssrn.4251277"
    }

@ARTICLE{Whybra2023-en,
      title    = "Sensitivity of standardised radiomics algorithms to mask generation across different software platforms",
      author   = "Whybra, Philip and Spezi, Emiliano",
      journal  = "Sci. Rep.",
      volume   =  13,
      number   =  1,
      pages    =  14419,
      month    =  sep,
      year     =  2023,
      language = "en",
      doi      = "10.1038/s41598-023-41475-w"
    }

@ARTICLE{Zwanenburg2020-ibsi,
      title     = "The Image Biomarker Standardisation Initiative: Standardised Quantitative Radiomics for High-Throughput Image-based Phenotyping",
      author    = "Zwanenburg, Alex and Valli{\`e}res, Martin and Abdalah, Mohamed A and Aerts, Hugo J W L and Andrearczyk, Vincent and Apte, Aditya and Ashrafinia, Shima and Bakas, Spyridon and Beukinga, Renger J and Boellaard, Ronald and Bogowicz, Margarita and Boldrini, Laura and Buvat, Ir{\`e}ne and Cook, Gary and Davatzikos, Christos and Depeursinge, Adrien and Desseroit, Marie-Claire and Dunet, Vincent and Echegaray, Santiago and El Naqa, Issam and Fave, Xenia and F{\"o}rster, Mathieu and Goh, Vicky and G{\"o}nen, Mehmet and Gollub, Marc and Grossmann, Patrick and Hakimi, Adam A and Hatt, Mathieu and Isensee, Fabian and Lambin, Philippe and Lee, Jeongjin and Leijenaar, Ralph T H and Liptrot, Matthew G and Losnegard, Are and Maier-Hein, Klaus H and Morin, Olivier and Mountz, James M and Nioche, Christophe and Orlhac, Fanny and Peet, Andrew W and Rao, Arvind and Scherer, Daniel and Schleiermacher, Geraldine and Schmidt-Richberg, Alexander and Schoemaker, Matthew and Shafiq-ul Hassan, Muhammad and Siegel, Eliot L and Silva, Mariana and Sousa, Joana and Traverso, Alberto and De Umbrajkar, Mahesh and Valentine, James W and van Griethuysen, Joost J M and Walsh, Sarah and Welk, Alexandra and Wilhelm, Christoph and Wright, Katia L and Yip, Stephen S F and Zeng, Jin and Fennessy, Fiona M and Mak, Raymond H and Pfaehler, Erik and Baessler, Benjamin",
      journal   = "Radiology",
      volume    =  295,
      number    =  2,
      pages     = "328--338",
      month     =  may,
      year      =  2020,
      language  = "en",
      doi       = "10.1148/radiol.2020191145"
    }

@ARTICLE{Nioche2018-ct,
      title     = "{LIFEx}: A Freeware for Radiomic Feature Calculation in
                   Multimodality Imaging to Accelerate Advances in the
                   Characterization of Tumor Heterogeneity",
      author    = "Nioche, Christophe and Orlhac, Fanny and Boughdad, Sarah and
                   Reuz{\'e}, Sylvain and Goya-Outi, Jessica and Robert, Charlotte and
                   Pellot-Barakat, Claire and Soussan, Michael and Frouin,
                   Fr{\'e}d{\'e}rique and Buvat, Ir{\`e}ne",
      journal   = "Cancer Res.",
      publisher = "AACR",
      volume    =  78,
      number    =  16,
      pages     = "4786--4789",
      month     =  aug,
      year      =  2018,
      language  = "en",
      doi       = "10.1158/0008-5472.can-18-0125"
    }
@article{YOUSEFIRIZI2024101745,
      title = {From code sharing to sharing of implementations: Advancing reproducible AI development for medical imaging through federated testing},
      journal = {Journal of Medical Imaging and Radiation Sciences},
      volume = {55},
      number = {4},
      pages = {101745},
      year = {2024},
      issn = {1939-8654},
      doi = {https://doi.org/10.1016/j.jmir.2024.101745},
      url = {https://www.sciencedirect.com/science/article/pii/S1939865424004764},
      author = {Fereshteh Yousefirizi and Annudesh Liyanage and Ivan S. Klyuzhin and Arman Rahmim},
      keywords = {Federated testing, Reproducibility, Artificial intelligence, PET segmentation, Preprocessing, Postprocessing, Deployment environment},
      abstract = {Background
The reproducibility crisis in AI research remains a significant concern. While code sharing has been acknowledged as a step toward addressing this issue, our focus extends beyond this paradigm. In this work, we explore “federated testing” as an avenue for advancing reproducible AI research and development especially in medical imaging. Unlike federated learning, where a model is developed and refined on data from different centers, federated testing involves models developed by one team being deployed and evaluated by others, addressing reproducibility across various implementations.
Methods
Our study follows an exploratory design aimed at systematically evaluating the sources of discrepancies in shared model execution for medical imaging and outputs on the same input data, independent of generalizability analysis. We distributed the same model code to multiple independent centers, monitoring execution in different runtime environments while considering various real-world scenarios for pre- and post-processing steps. We analyzed deployment infrastructure by comparing the impact of different computational resources (GPU vs. CPU) on model performance. To assess federated testing in AI models for medical imaging, we performed a comparative evaluation across different centers, each with distinct pre- and post-processing steps and deployment environments, specifically targeting AI-driven positron emission tomography (PET) imaging segmentation. More specifically, we studied federated testing for an AI-based model for surrogate total metabolic tumor volume (sTMTV) segmentation in PET imaging: the AI algorithm, trained on maximum intensity projection (MIP) data, segments lymphoma regions and estimates sTMTV.
Results
Our study reveals that relying solely on open-source code sharing does not guarantee reproducible results due to variations in code execution, runtime environments, and incomplete input specifications. Deploying the segmentation model on local and virtual GPUs compared to using Docker containers showed no effect on reproducibility. However, significant sources of variability were found in data preparation and pre-/post- processing techniques for PET imaging. These findings underscore the limitations of code sharing alone in achieving consistent and accurate results in federated testing.
Conclusion
Achieving consistently precise results in federated testing requires more than just sharing models through open-source code. Comprehensive pipeline sharing, including pre- and post-processing steps, is essential. Cloud-based platforms that automate these processes can streamline AI model testing across diverse locations. Standardizing protocols and sharing complete pipelines can significantly enhance the robustness and reproducibility of AI models.}
}
